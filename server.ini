;select count(*) as count,dist(id) as dist_id,sum(value) as sum_value from test group by 10m group time 1i save as test
[server]
; 服务器唯一ID, 请保持唯一
name = Server01
; 监听IP
host = 127.0.0.1
; 端口
port = 9203

; 在退出时把所有数据推送到redis,ssdb里
flush_at_shutdown = true

; 请确保可写, 当程序退出时, flush_at_shutdown = false 或者 redis/ssdb 保存失败时dump数据目录
dump_path = /tmp/

; redis中数据合并时间间隔（毫秒), 默认3000ms - 3秒
merge_time_ms = 3000

; 存储引擎, 支持 sqlite, leveldb, redis (ssdb)
data_type = 'redis'

; 如果是 leveldb 或 sqlite 填写目录, 如果是 redis 或 ssdb 填写 ip:port, 如果 redis 是集群请用逗号（,）隔开
data_link = '127.0.0.1:6379'

[redis]
; 除支持 redis 还支持 ssdb（持久存储, 无内存容量限制), see http://ssdb.io/
; 支持集群, 如下
; hosts[] = 127.0.0.1:6381
; hosts[] = 127.0.0.1:6382
; hosts[] = 127.0.0.1:6383
host = 127.0.0.1
port = 6379


[output]
; 输出类似, 支持 fluent, mysql, influxdb, mongo
type = fluent
link = tcp://127.0.0.1:12101

; 输出的表,tag前缀
prefix = merged.

[manager]
; 管理http接口监听端口,默认 127.0.0.1
host = 127.0.0.1
; 管理http接口端口, 默认9200
port = 9200


[remote]
; 通过 telnet 127.0.0.1 9599 连接到服务器上, 可执行调试相关代码. see https://github.com/swoole/remote-shell
;host = 127.0.0.1
; 管理http接口端口, 默认9200
;port = 9599

[conf]
;所有参数见 http://wiki.swoole.com/wiki/page/274.html

; 日志记录目录, 也可以通过 -l /data/log/swoole.log 参数设置
;log_file        = /data/log/swoole.log

; 守护进程化, 也可以通过 -d 参数设置
;daemonize      = 1

backlog       = 128

; 处理分块数据的进程数
worker_num    = 4
max_request   = 0

; 执行的子进程的用户和组
;user     = www
;group    = www

; 重定向Worker进程的文件系统根目录
;chroot   = /data/server/

; 线程数,设成成cpu数的1-4倍
;reactor_num     = 2

;值必须小余 ulimit -n 的值
;max_conn        = 10000

; 处理汇总数据的进程数
task_worker_num  = 4
task_max_request = 0

package_max_length = 10000000

; 启用心跳检测，此选项表示每隔多久轮循一次，单位为秒
heartbeat_check_interval = 30

; 表示连接最大允许空闲的时间, 需要比 heartbeat_check_interval 大
heartbeat_idle_time = 160

[php]
error_reporting = 7
timezone        = PRC
